<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://documentation.neuralseek.com/reference_material/tuning_guide/tuning_guide/">
    <link rel="shortcut icon" href="/images/ns-white.svg">
    
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&amp;display=swap" rel="stylesheet">
    <title>KnowledgeBase Tuning - NeuralSeek Documentation</title>
    <link href="/css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="/css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="/css/colors.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/highlight-github-theme.css">
    <link rel="stylesheet" href="/css/highlightjs-copy.css">
    <link href="/css/base.css" rel="stylesheet">
    <link href="../../../css/override.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="/js/jquery-3.2.1.min.js"></script>
    <script src="/js/bootstrap-3.3.7.min.js"></script>
    <script src="/js/highlight.min.js"></script>
    <script src="/js/highlightjs-copy.min.js"></script>
    
    <base target="_top">
    <script>
      hljs.addPlugin(new CopyButtonPlugin());
      hljs.configure({languages:[]});
      hljs.highlightAll();
    </script>
    <script>
      var base_url = '../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Overview", url: "#overview", children: [
          ]},
          {title: "Bootstrapping your Agent", url: "#bootstrapping-your-agent", children: [
          ]},
          {title: "Improving Answers", url: "#improving-answers", children: [
              {title: "Understanding Generated Answers", url: "#understanding-generated-answers" },
              {title: "Improving Source Documentation", url: "#improving-source-documentation" },
              {title: "Hybrid and Vector Search", url: "#hybrid-and-vector-search" },
              {title: "Answer Variations", url: "#answer-variations" },
          ]},
          {title: "Filtering Documentation", url: "#filtering-documentation", children: [
          ]},
          {title: "Avoiding Timeouts", url: "#avoiding-timeouts", children: [
          ]},
          {title: "KnowledgeBase Translation", url: "#knowledgebase-translation", children: [
          ]},
          {title: "Using Multiple Data Sources", url: "#using-multiple-data-sources", children: [
          ]},
        ];

    </script>
    <script src="/js/base.js"></script>
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-LE5XX6X6Z7"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
      
        gtag('config', 'G-LE5XX6X6Z7');
      </script> 
 <link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }</style> <script src="../../../assets/javascripts/glightbox.min.js"></script></head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    <h2 id="overview">Overview<a class="headerlink" href="#overview" title="Permanent link"></a></h2>
<p>This guide provides information on improving answers from the connected KnowledgeBase - Your <strong>ground truth</strong>. </p>
<p>Use this guide to help get started, improve answers, and learn about some best practices.</p>
<h2 id="bootstrapping-your-agent">Bootstrapping your Agent<a class="headerlink" href="#bootstrapping-your-agent" title="Permanent link"></a></h2>
<p>NeuralSeek aims to make bulk-tuning easy, offering different methods for Subject-Matter Experts (SMEs) to collaborate and curate answers.</p>
<p><a class="glightbox" href="../images/ready_to_answer.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/ready_to_answer.png" /></a></p>
<p>To bootstrap your agent, you may find these options on the home screen.</p>
<ul>
<li>Auto-Generate Questions: This will run a query against your connected KnowledgeBase and attempt to generate a list of relevant questions to your subject matter, and then mimics the below option</li>
<li>Manually Input Questions: Accepts a list of newline-separated questions, and will perform a Seek action with each question. This populates the Curate tab, while also generating a report spreadsheet that can be distributed among SMEs to weigh in on answers and make edits. (you can also export a similar spreadsheet from the Curate tab)</li>
</ul>
<p>Finally, you can upload the resulting edits via the "Upload Curated Q&amp;A" option. Congratulations! You've quick-tuned your agent to your most important or relevant subjects.</p>
<h2 id="improving-answers">Improving Answers<a class="headerlink" href="#improving-answers" title="Permanent link"></a></h2>
<p>There are many ways to improve generated answers. This can include:</p>
<ul>
<li>Utilizing Semantic Scores to monitor or block low-quality answers</li>
<li>Updating or improving documentation - Answers are only as good as the ground truth!</li>
<li>Controlling the amount of information sent to the LLM</li>
<li>Choosing Lucene VS Vector search (we also support a Hybrid mode!)</li>
</ul>
<h3 id="understanding-generated-answers">Understanding Generated Answers<a class="headerlink" href="#understanding-generated-answers" title="Permanent link"></a></h3>
<p>A common issue with LLMs: giving answers that are irrelevant or inaccurate. NeuralSeek makes it easier to handle these cases.</p>
<p>To reduce low quality answers, start on the Seek tab: Ask a question. </p>
<p>To help analyze your answers, take a look at the following:</p>
<p><strong>Review the Semantic Score</strong></p>
<ul>
<li>Is it low? (below 20%) - Perhaps your documentation does not compare well to the question posed, or there is many source jumps / unattributed terms</li>
<li>Is it high? (above 60%) - If the answer is low quality - does your documentation have conflicting answers, or very similar terminology to the given query?</li>
</ul>
<p><strong>Understand the Semantic Analysis text</strong></p>
<ul>
<li>This is meant to offer insight into the scores given - e.g. a lot of terms from many documents, or primarily one source of documentation.</li>
</ul>
<p><strong>Review the KB scores</strong></p>
<ul>
<li>Low Coverage - There is not many documents matching the query</li>
<li>High Coverage - There are many documents matching the query, or few documents that match exactly</li>
<li>Low Confidence - The source KB thinks we do not have good matches to the query</li>
<li>High Confidence - The source KB has found good query matches, but may not answer the query directly</li>
</ul>
<p><strong>Review the documentation sources</strong></p>
<ul>
<li>Expand the accordions below to see the actual source documentation provided by the KnowledgeBase. This is what is sent to the LLM for language generation.</li>
<li>Improve the documentation: If the source documentation does not directly answer the question, updating the source content will almost always help.</li>
<li>Adjust the Document Score Range: This widens, or shrinks, the top % of documents that will be considered.</li>
<li>Adjust the Snippet Size: This can help narrow passages out of blocks of unrelated text, or widen the scope for large paragraphs that only mention the subject of your query once.</li>
<li>Narrow the Max Documents per Seek: This can help target only the best scoring/matching documents, and avoid confusing some LLMs with a slew of document choices.</li>
</ul>
<p>To give some examples: Here, we've set the maximum allowed documents to one with snippet size set to 2000 (the largest):</p>
<p><a class="glightbox" href="../images/1_doc_2000_snippet_size.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/1_doc_2000_snippet_size.png" /></a>
<a class="glightbox" href="../images/seek_with_1_doc_max.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/seek_with_1_doc_max.png" /></a></p>
<p>Some things to notice:</p>
<ul>
<li>There is only one document result</li>
<li>The semantic score is high</li>
<li>If you expand the document accordion - there is a lot of text returned in this passage</li>
</ul>
<p>In the next example, we've set the maximum allowed documents to three with snippet size set to 400 (relatively small):</p>
<p><a class="glightbox" href="../images/3_doc_400_snippet_size.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/3_doc_400_snippet_size.png" /></a>
<a class="glightbox" href="../images/seek_with_2_doc_max.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/seek_with_2_doc_max.png" /></a></p>
<p>We now have:</p>
<ul>
<li>One additional document (total of 2)</li>
<li>A lower semantic score</li>
<li>More source jumps in the answer</li>
</ul>
<p>Generally speaking, and for most use cases, it is better to provide a few top quality documents, versus many low quality or unrelated documents, to the LLM for answer generation. Using these settings can help focus or widen the documentation as needed per use-case.</p>
<h3 id="improving-source-documentation">Improving Source Documentation<a class="headerlink" href="#improving-source-documentation" title="Permanent link"></a></h3>
<p>One of the best ways to directly improve answer generation! Here's an example:</p>
<blockquote>
<p>A customer had a very large document, with an Acronym and a definition that was near the top of the document. The acronym was used hundreds of times across many pages. The source KB typically returned the paragraph with the most uses (matches) of the acronym, despite the overall snippet not answering the question directly. To improve the results, we split the document by pages, increased the score range and lowered the snippet size, allowing the KB to effortlessly bring back the relevant document passages while enabling the customer to control the amount of documentation fed to the LLM.</p>
</blockquote>
<p>Generally speaking, the best practice is to have individual documents that speak directly to the subject you want to answer.</p>
<h3 id="hybrid-and-vector-search">Hybrid and Vector Search<a class="headerlink" href="#hybrid-and-vector-search" title="Permanent link"></a></h3>
<p>NeuralSeek supports Vector searching on some KnowledgeBase platforms. (see the Supported KnowledgeBases page for details)</p>
<p><a class="glightbox" href="../images/hybrid_vector.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/hybrid_vector.png" /></a></p>
<p>Vector Similarity searching is finding "similar" words, where Lucene is "exact matching" terms. For example, if you search for <code>Animal</code> you could also get results like <code>Cat, Dog, Mouse, Lizard</code>. It's not recommended to use only vector search for corporate-based RAG, as the chance of hallucination is incredibly high. For example - a user searches for <code>8.1.0</code>. Lucene will bring back only results with the exact term, where vector similarity may also return <code>8.0.1</code>, <code>8.10</code>, or similar.</p>
<p>Choosing the Hybrid implementation is recommended if using vector similarity - NeuralSeek will boost the Lucene results, offering Vector results as a sort of "fallback". This can help some use cases.</p>
<h3 id="answer-variations">Answer Variations<a class="headerlink" href="#answer-variations" title="Permanent link"></a></h3>
<p>Generative AI often times will generate small variations for the same query.</p>
<p>Two ways to combat this:</p>
<ul>
<li>Set the "edited" answer cache setting to 1, and edit the answer on the curate tab.</li>
<li>Set the "normal" answer cache setting to 1. </li>
</ul>
<p>Both of these options will cause NeuralSeek to output consistent, identical answers. This also reduces the amount of language generation calls.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Edited answers always return a Semantic Score of 100%.  </p>
</div>
<h2 id="filtering-documentation">Filtering Documentation<a class="headerlink" href="#filtering-documentation" title="Permanent link"></a></h2>
<p>Many times there is a large amount of documents, or many data sources / types, to manage. Filtering can narrow down results in a large pool of data.</p>
<p>You may filter on any metadata field available from the KB. Simply set the desired field in the KnowledgeBase Connection settings, and pass a value for which to filter in the Seek call. </p>
<p>For example - Using <code>metadata.document_type</code> as the field, and <code>PDF</code> as the value, will return only documents with this field set to PDF. Use comma-separated values for an <code>OR</code> filter.</p>
<div class="admonition note">
<p class="admonition-title">Watson Discovery users</p>
<p>To filter by Collection ID: Under KnowledgeBase Connection, enable the Advanced Schema, and manually input <code>collection_id</code> in the filter field</p>
<p>DQL_Pushdown is also an option for Discovery users - Select this option, and pass <a href="https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-dql-overview">DQL syntax</a> in the filter value on Seek calls.</p>
</div>
<p>Another tool to help target the best quality documentation available is to utilize the "Re-Sort values list" option. This allows you to prioritize certain documents over others - maybe use a collection ID to prioritize internal uploaded documentation over a general company website scrape, or perhaps PDFs have more concise data than your DOCX files. <strong>This allows you to prioritize values without entirely excluding other values.</strong></p>
<h2 id="avoiding-timeouts">Avoiding Timeouts<a class="headerlink" href="#avoiding-timeouts" title="Permanent link"></a></h2>
<p>NeuralSeek has a limited amount of time to generate a response, as well as a context window that the LLM dictates. Sometimes, the LLM generates large answers and cannot finish its thought before the space runs out, we exceed the chatbot platform timeout, or we exceed the KB's timeout. This will occasionally cause the generated answer to have a dangling sentence near the end - NeuralSeek looks for these dangling responses and trims them back to a logical sentence.</p>
<p>Contributing factors can include:</p>
<ul>
<li>KnowledgeBase retrieval speed</li>
<li>LLM generation speed</li>
<li>Chatbot settings - timeout settings, etc</li>
<li>Network latency</li>
</ul>
<p>Some settings that may help:</p>
<ul>
<li>Reducing the maximum number of documents returned from the KB</li>
<li>Using a faster LLM</li>
<li>Reducing LLM verbosity in the NeuralSeek Configuration</li>
<li>Increasing the chatbot timeout threshold</li>
<li>Provisioning services in the same regions</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When adjusting the verbosity setting, for shorter answers change the verbosity setting to "more concise". For longer/more descriptive answers change the verbosity setting to "more verbose".</p>
</div>
<h2 id="knowledgebase-translation">KnowledgeBase Translation<a class="headerlink" href="#knowledgebase-translation" title="Permanent link"></a></h2>
<p>It can be challenging to work with multiple languages. For example - you want the LLM to respond in Spanish, but the source documentation is in English. NeuralSeek can solve this: In the Platform Preferences configuration, enable <code>Translate into KB Language</code>, and set the desired output language. </p>
<p><a class="glightbox" href="../images/platform_preferences.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/platform_preferences.png" /></a></p>
<p>This allows NeuralSeek to:</p>
<ul>
<li>Accept a question in Spanish (for example)</li>
<li>Translate to English (source documentation language)</li>
<li>Perform a KB search in English</li>
<li>Generate an Answer in English</li>
<li>Translate the Answer to Spanish</li>
</ul>
<div class="admonition warning">
<p class="admonition-title">For Bring-your-own LLM users</p>
<p>When using the cross-language feature of NeuralSeek, some LLMs will not excel at this. You will need to use a powerful model like GPT, Llama 70b, or Mixtral.</p>
</div>
<p>You can set NeuralSeek's output language to "Match Input" to respond in the same language as the query. Another choice is to have the chatbot control the language returned. Some chatbots support passing the language dynamically as a context variable to the NeuralSeek API. The source of the context variable can be the web browser language or part of the chatbot's URL that tells you the user's language.</p>
<p>Example from watsonx Assistant:</p>
<p><a class="glightbox" href="../images/extension_config.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/extension_config.png" /></a></p>
<h2 id="using-multiple-data-sources">Using Multiple Data Sources<a class="headerlink" href="#using-multiple-data-sources" title="Permanent link"></a></h2>
<p>NeuralSeek allows you to use multiple configurations on-demand, effectively overriding any settings currently in the Configure tab. This is useful if you want to use multiple KB sources, project IDs, or similarly exceed the UI limitations.</p>
<p><a class="glightbox" href="../images/download_settings.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="download settings" src="../images/download_settings.png" /></a></p>
<p>Simply configure NeuralSeek with the desired parameters, save, and then "Download Settings" as pictured.</p>
<p>This will download a <code>.dat</code> file, containing an encoded string of all current settings - including KB details, project IDs, LLMs, etc.</p>
<p>On Seek API calls, set <code>options.override</code> to this encoded string - Effectively using these saved settings for this Seek call, ignoring "current" settings in the UI.</p>

  <br>
</div>

<footer class="container-fluid wm-page-content"><p>â’¸ 2024 NeuralSeek, all rights reserved.</p>
</footer>

<script src="/scripts/watson.js"></script>
<script> if(is_top_frame) loadWatson(); </script>
<script>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});</script></body>
</html>