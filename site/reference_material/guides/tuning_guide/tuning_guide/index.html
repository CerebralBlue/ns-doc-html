
<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://documentation.neuralseek.com/reference_material/guides/tuning_guide/tuning_guide/">
    <link rel="shortcut icon" href="../../../../img/ns-white.svg">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&amp;display=swap" rel="stylesheet">
    <title>KnowledgeBase Tuning - NeuralSeek Documentation</title>

  <meta property="og:title" content="KnowledgeBase Tuning" />
  <meta property="og:description" content="NeuralSeek Documentation" />
    <link href="../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../css/colors.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../css/highlight-github-theme.css">
    <link rel="stylesheet" href="../../../../css/highlightjs-copy.css">
    <link href="../../../../css/base.css" rel="stylesheet">
    <link href="../../../../css/override.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../js/highlight.min.js"></script>
    <script src="../../../../js/highlightjs-copy.min.js"></script>
    <script src="../../../../js/elasticlunr.min.js"></script>
      
    <base target="_top">
    <script>
      hljs.addPlugin(new CopyButtonPlugin());
      hljs.configure({languages:[]});
      hljs.highlightAll();
    </script>
    <script>
  var base_url = '../../../..';
  var is_top_frame = false;
    
    var pageToc = [
      {title: "Overview", url: "#overview", children: [
      ]},
      {title: "Bootstrapping your Agent", url: "#bootstrapping-your-agent", children: [
      ]},
      {title: "Improving Answers", url: "#improving-answers", children: [
          {title: "Understanding Generated Answers", url: "#understanding-generated-answers" },
          {title: "Optimal Settings", url: "#optimal-settings" },
          {title: "Improving Source Documentation", url: "#improving-source-documentation" },
          {title: "Hybrid and Vector Search", url: "#hybrid-and-vector-search" },
          {title: "Answer Variations", url: "#answer-variations" },
      ]},
      {title: "Filtering Documentation", url: "#filtering-documentation", children: [
      ]},
      {title: "Avoiding Timeouts", url: "#avoiding-timeouts", children: [
      ]},
      {title: "KnowledgeBase Translation", url: "#knowledgebase-translation", children: [
      ]},
      {title: "Using Multiple Data Sources", url: "#using-multiple-data-sources", children: [
      ]},
    ];

</script>
    <script src="../../../../js/base.js?v=2"></script>
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-LE5XX6X6Z7"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
      
        gtag('config', 'G-LE5XX6X6Z7');
      </script> 
 <link href="../../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }</style> <script src="../../../../assets/javascripts/glightbox.min.js"></script></head>

<body class="wm-top-page">
<nav class="navbar wm-page-top-frame">
  <div class="container-fluid wm-top-container">
    
    <div class="wm-top-tool pull-right wm-vcenter">
      <form class="dropdown wm-vcentered" id="wm-search-form" action="../../../../search.html">
        
        <button id="wm-search-show" class="btn btn-sm btn-default" type="submit"
          ><i class="fa fa-search" aria-hidden="true"></i></button>

        <div class="input-group input-group-sm wm-top-search">
          <input type="text" name="q" class="form-control" id="mkdocs-search-query" placeholder="Search" autocomplete="off">
          <span class="input-group-btn" role="search">
            
            <button class="btn btn-default dropdown-toggle collapse" data-toggle="dropdown" type="button"><span class="caret"></span></button>
            <ul id="mkdocs-search-results" class="dropdown-menu dropdown-menu-right"></ul>
            <button id="wm-search-go" class="btn btn-default" type="submit"><i class="fa fa-search" aria-hidden="true"></i></button>
          </span>
        </div>
      </form>
    </div>

    
    <div class="wm-top-tool wm-vcenter pull-left wm-small-left">
      <button id="wm-toc-button" type="button" class="btn btn-sm btn-default wm-vcentered"><i class="fa fa-bars" aria-hidden="true"></i></button>
    </div>
    
    
    
      <div class="wm-top-tool wm-vcenter pull-right">
  <div class="wm-select wm-vcentered">
    
    <button class="wm-header__button wm-icon" aria-label="">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.52 17.52 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04M18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12m-2.62 7 1.62-4.33L19.12 17h-3.24Z"/></svg>
    </button>
    <div class="wm-select__inner">
      <ul class="wm-select__list">
        
          <li class="wm-select__item">
            
              <a href="/reference_material/guides/tuning_guide/tuning_guide/" hreflang="English" class="wm-select__link">
              English
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    

    
    

    
    <a href="https://documentation.neuralseek.com/" class="wm-top-brand wm-top-link wm-vcenter">
      
      <img class="wm-top-logo" src="../../../../img/ns-white.svg"/>
      
      <div class="wm-top-title">
        NeuralSeek Documentation<br>
        
      </div>
    </a>
  </div>
</nav>

<div id="main-content" class="wm-page-top-frame">
    
<nav class="wm-toc-pane">
  
  <ul class="wm-toctree">
        
      
      
      
      
      
      
      
      

<li class="wm-toc-li wm-toc-lev0 wm-toc-opener  "><span class="wm-toc-text">About Cerebral Blue</span>
</li>
<li class="wm-toc-li-nested collapse ">
  <ul class="wm-toctree">
      

<li class="wm-toc-li wm-toc-lev1   "><a href="https://cerebralblue.com/" class="wm-article-link wm-toc-text">Home Page</a>
</li>
      

<li class="wm-toc-li wm-toc-lev1   "><a href="https://cerebralblue.com/about-us/" class="wm-article-link wm-toc-text">About Us</a>
</li>
      

<li class="wm-toc-li wm-toc-lev1   "><a href="https://cerebralblue.com/contact-us/" class="wm-article-link wm-toc-text">Contact Us</a>
</li>
      

<li class="wm-toc-li wm-toc-lev1   "><a href="https://cerebralblue.com/contact-us/" class="wm-article-link wm-toc-text">Partnerships</a>
</li>
  </ul>
</li>

        

<li class="wm-toc-li wm-toc-lev0   "><a href="../../../../" class="wm-article-link wm-toc-text">NeuralSeek Overview</a>
</li>
        
      
      
      
      
      
      
      
      
      
      

<li class="wm-toc-li wm-toc-lev0 wm-toc-opener  "><span class="wm-toc-text">Main Features</span>
</li>
<li class="wm-toc-li-nested collapse ">
  <ul class="wm-toctree">
      

<li class="wm-toc-li wm-toc-lev1   "><a href="../../../../main_features/user_interface/user_interface/" class="wm-article-link wm-toc-text">NeuralSeek User Interface</a>
</li>
      

<li class="wm-toc-li wm-toc-lev1   "><a href="../../../../main_features/conversational_capabilities/conversational_capabilities/" class="wm-article-link wm-toc-text">Conversational Capabilities</a>
</li>
      

<li class="wm-toc-li wm-toc-lev1   "><a href="../../../../main_features/language_capabilities/language_capabilities/" class="wm-article-link wm-toc-text">Language Capabilities</a>
</li>
      

<li class="wm-toc-li wm-toc-lev1   "><a href="../../../../main_features/data_management/data_management/" class="wm-article-link wm-toc-text">Data Management</a>
</li>
      

<li class="wm-toc-li wm-toc-lev1   "><a href="../../../../main_features/advanced_features/advanced_features/" class="wm-article-link wm-toc-text">Advanced Features</a>
</li>
  </ul>
</li>

        
      
      
      
      
      
      
      
      

<li class="wm-toc-li wm-toc-lev0 wm-toc-opener  "><span class="wm-toc-text">Integrations</span>
</li>
<li class="wm-toc-li-nested collapse ">
  <ul class="wm-toctree">
      

<li class="wm-toc-li wm-toc-lev1   "><a href="../../../../integrations/supported_knowledgebases/supported_knowledgebases/" class="wm-article-link wm-toc-text">Supported KnowledgeBases</a>
</li>
      

<li class="wm-toc-li wm-toc-lev1   "><a href="../../../../integrations/supported_llms/supported_llms/" class="wm-article-link wm-toc-text">Supported LLMs</a>
</li>
      

<li class="wm-toc-li wm-toc-lev1   "><a href="../../../../integrations/supported_virtual_agents/supported_virtual_agents/" class="wm-article-link wm-toc-text">Supported Virtual Agents</a>
</li>
      

<li class="wm-toc-li wm-toc-lev1   "><a href="../../../../integrations/rest_api/rest_api/" class="wm-article-link wm-toc-text">REST API</a>
</li>
  </ul>
</li>

        
      
      
      
      

<li class="wm-toc-li wm-toc-lev0 wm-toc-opener  wm-toc-open"><span class="wm-toc-text">Reference Material</span>
</li>
<li class="wm-toc-li-nested collapse in">
  <ul class="wm-toctree">
      
      
      
      
      

<li class="wm-toc-li wm-toc-lev1 wm-toc-opener  "><span class="wm-toc-text">mAIstro Features</span>
</li>
<li class="wm-toc-li-nested collapse ">
  <ul class="wm-toctree">
      

<li class="wm-toc-li wm-toc-lev2   "><a href="../../../../reference_material/maistro/maistro/" class="wm-article-link wm-toc-text">Visual Editor</a>
</li>
      

<li class="wm-toc-li wm-toc-lev2   "><a href="../../../../reference_material/maistro/ntl_overview/" class="wm-article-link wm-toc-text">NTL Overview</a>
</li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      

<li class="wm-toc-li wm-toc-lev2 wm-toc-opener  "><span class="wm-toc-text">All NTL Functions</span>
</li>
<li class="wm-toc-li-nested collapse ">
  <ul class="wm-toctree">
      

<li class="wm-toc-li wm-toc-lev3   "><a href="../../../../reference_material/maistro/ntl/get_data/" class="wm-article-link wm-toc-text">Get data</a>
</li>
      

<li class="wm-toc-li wm-toc-lev3   "><a href="../../../../reference_material/maistro/ntl/upload_data/" class="wm-article-link wm-toc-text">Upload data</a>
</li>
      

<li class="wm-toc-li wm-toc-lev3   "><a href="../../../../reference_material/maistro/ntl/generate_data/" class="wm-article-link wm-toc-text">Generate data</a>
</li>
      

<li class="wm-toc-li wm-toc-lev3   "><a href="../../../../reference_material/maistro/ntl/extract_data/" class="wm-article-link wm-toc-text">Extract data</a>
</li>
      

<li class="wm-toc-li wm-toc-lev3   "><a href="../../../../reference_material/maistro/ntl/database_connections/" class="wm-article-link wm-toc-text">Database connections</a>
</li>
      

<li class="wm-toc-li wm-toc-lev3   "><a href="../../../../reference_material/maistro/ntl/control_flow/" class="wm-article-link wm-toc-text">Control flow</a>
</li>
      

<li class="wm-toc-li wm-toc-lev3   "><a href="../../../../reference_material/maistro/ntl/guardrails/" class="wm-article-link wm-toc-text">Guardrails</a>
</li>
      

<li class="wm-toc-li wm-toc-lev3   "><a href="../../../../reference_material/maistro/ntl/system_variables/" class="wm-article-link wm-toc-text">System variables</a>
</li>
      
      
      
      
      
      
      

<li class="wm-toc-li wm-toc-lev3 wm-toc-opener  "><span class="wm-toc-text">Modify Data</span>
</li>
<li class="wm-toc-li-nested collapse ">
  <ul class="wm-toctree">
      

<li class="wm-toc-li wm-toc-lev4   "><a href="../../../../reference_material/maistro/ntl/modify_data/Jsontools/" class="wm-article-link wm-toc-text">JSON Toolbox</a>
</li>
      

<li class="wm-toc-li wm-toc-lev4   "><a href="../../../../reference_material/maistro/ntl/modify_data/Stringtools/" class="wm-article-link wm-toc-text">String Toolbox</a>
</li>
      

<li class="wm-toc-li wm-toc-lev4   "><a href="../../../../reference_material/maistro/ntl/modify_data/Transform/" class="wm-article-link wm-toc-text">Transform</a>
</li>
  </ul>
</li>

      

<li class="wm-toc-li wm-toc-lev3   "><a href="../../../../reference_material/maistro/ntl/send_data/" class="wm-article-link wm-toc-text">Send data</a>
</li>
  </ul>
</li>

  </ul>
</li>

      
      
      
      
      
      
      
      
      
      
      
      
      
      
      

<li class="wm-toc-li wm-toc-lev1 wm-toc-opener  wm-toc-open"><span class="wm-toc-text">Guides</span>
</li>
<li class="wm-toc-li-nested collapse in">
  <ul class="wm-toctree">
      

<li class="wm-toc-li wm-toc-lev2   "><a href="../../../../reference_material/guides/backup_and_restore/backup_and_restore/" class="wm-article-link wm-toc-text">Backup and Restore</a>
</li>
      

<li class="wm-toc-li wm-toc-lev2   "><a href="../../../../reference_material/guides/elasticseach_vector_model/elasticsearch_vector_model/" class="wm-article-link wm-toc-text">Configuring ElasticSearch for Vector Search</a>
</li>
      

<li class="wm-toc-li wm-toc-lev2   "><a href="../../../../reference_material/guides/implementing_feedback/implementing_feedback/" class="wm-article-link wm-toc-text">Implementing Feedback</a>
</li>
      

<li class="wm-toc-li wm-toc-lev2   "><a href="../../../../reference_material/guides/pinecone_configuration/pinecone/" class="wm-article-link wm-toc-text">Pinecone Integration with NeuralSeek</a>
</li>
      

<li class="wm-toc-li wm-toc-lev2   "><a href="../../../../reference_material/guides/proposals/proposals/" class="wm-article-link wm-toc-text">Using Proposals</a>
</li>
      

<li class="wm-toc-li wm-toc-lev2   "><a href="../../../../reference_material/guides/training_virtual_agents/training_virtual_agents/" class="wm-article-link wm-toc-text">Training Virtual Agents</a>
</li>
      

<li class="wm-toc-li wm-toc-lev2  wm-current "><a href="../../../../reference_material/guides/tuning_guide/tuning_guide/" class="wm-article-link wm-toc-text">KnowledgeBase Tuning</a>
</li>
  </ul>
</li>

      

<li class="wm-toc-li wm-toc-lev1   "><a href="../../../../reference_material/configuration/configuration/" class="wm-article-link wm-toc-text">Configuration Details</a>
</li>
      

<li class="wm-toc-li wm-toc-lev1   "><a href="../../../../reference_material/governance/governance/" class="wm-article-link wm-toc-text">Governance Metrics</a>
</li>
  </ul>
</li>

        

<li class="wm-toc-li wm-toc-lev0   "><a href="../../../../plans/" class="wm-article-link wm-toc-text">Available NeuralSeek Plans</a>
</li>
        

<li class="wm-toc-li wm-toc-lev0   "><a href="../../../../data_security_and_privacy/" class="wm-article-link wm-toc-text">Data Security and Privacy</a>
</li>
        

<li class="wm-toc-li wm-toc-lev0   "><a href="../../../../changelog/" class="wm-article-link wm-toc-text">Changelog</a>
</li>
  </ul>
</nav>

  <div class="wm-content-pane">
    <div class="container-fluid wm-page-content">
        
        <div class="wm-page-real-content">
          <a name="_top"></a>  
          
          <h2 id="overview">Overview<a class="headerlink" href="#overview" title="Permanent link"></a></h2>
<p>This guide provides information on improving answers from the connected KnowledgeBase - Your <strong>ground truth</strong>. </p>
<p>Use this guide to help get started, improve answers, and learn about some best practices.</p>
<h2 id="bootstrapping-your-agent">Bootstrapping your Agent<a class="headerlink" href="#bootstrapping-your-agent" title="Permanent link"></a></h2>
<p>NeuralSeek aims to make bulk-tuning easy, offering different methods for Subject-Matter Experts (SMEs) to collaborate and curate answers.</p>
<p><a class="glightbox" href="../images/ready_to_answer.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/ready_to_answer.png" /></a></p>
<p>To bootstrap your agent, you may find these options on the home screen.</p>
<ul>
<li>Auto-Generate Questions: This will run a query against your connected KnowledgeBase and attempt to generate a list of relevant questions to your subject matter, and then mimics the below option</li>
<li>Manually Input Questions: Accepts a list of newline-separated questions, and will perform a Seek action with each question. This populates the Curate tab, while also generating a report spreadsheet that can be distributed among SMEs to weigh in on answers and make edits. (you can also export a similar spreadsheet from the Curate tab)</li>
</ul>
<p>Finally, you can upload the resulting edits via the "Upload Curated Q&amp;A" option. Congratulations! You've quick-tuned your agent to your most important or relevant subjects.</p>
<h2 id="improving-answers">Improving Answers<a class="headerlink" href="#improving-answers" title="Permanent link"></a></h2>
<p>There are many ways to improve generated answers. This can include:</p>
<ul>
<li>Utilizing Semantic Scores to monitor or block low-quality answers</li>
<li>Updating or improving documentation - Answers are only as good as the ground truth!</li>
<li>Controlling the amount of information sent to the LLM and "force" answers from the KnowledgeBase</li>
<li>Choosing Lucene VS Vector search (we also support a Hybrid mode!)</li>
</ul>
<h3 id="understanding-generated-answers">Understanding Generated Answers<a class="headerlink" href="#understanding-generated-answers" title="Permanent link"></a></h3>
<p>A common issue with LLMs: giving answers that are irrelevant or inaccurate. NeuralSeek makes it easier to handle these cases.</p>
<p>To reduce low quality answers, start on the Seek tab: Ask a question. </p>
<p>To help analyze your answers, take a look at the following:</p>
<p><strong>Review the Semantic Score</strong></p>
<ul>
<li>Is it low? (below 20%) - Perhaps your documentation does not compare well to the question posed, or there is many source jumps / unattributed terms</li>
<li>Is it high? (above 60%) - If the answer is low quality - does your documentation have conflicting answers, or very similar terminology to the given query?</li>
</ul>
<p><strong>Understand the Semantic Analysis text</strong></p>
<ul>
<li>This is meant to offer insight into the scores given - e.g. a lot of terms from many documents, or primarily one source of documentation.</li>
</ul>
<p><strong>Review the KB scores</strong></p>
<ul>
<li>Low Coverage - There is not many documents matching the query</li>
<li>High Coverage - There are many documents matching the query, or few documents that match exactly</li>
<li>Low Confidence - The source KB thinks we do not have good matches to the query</li>
<li>High Confidence - The source KB has found good query matches, but may not answer the query directly</li>
</ul>
<p><strong>Review the documentation sources</strong></p>
<ul>
<li>Expand the accordions below to see the actual source documentation provided by the KnowledgeBase. This is what is sent to the LLM for language generation.</li>
<li>Improve the documentation: If the source documentation does not directly answer the question, updating the source content will almost always help.</li>
<li>Adjust the Document Score Range: This widens, or shrinks, the top % of documents that will be considered.</li>
<li>Adjust the Snippet Size: This can help narrow passages out of blocks of unrelated text, or widen the scope for large paragraphs that only mention the subject of your query once.</li>
<li>Narrow the Max Documents per Seek: This can help target only the best scoring/matching documents, and avoid confusing some LLMs with a slew of information.</li>
</ul>
<p>To give some examples: Here, we've set the maximum allowed documents to one with snippet size set to 2000 (the largest):</p>
<p><a class="glightbox" href="../images/1_doc_2000_snippet_size.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/1_doc_2000_snippet_size.png" /></a>
<a class="glightbox" href="../images/seek_with_1_doc_max.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/seek_with_1_doc_max.png" /></a></p>
<p>Some things to notice:</p>
<ul>
<li>There is only one document result</li>
<li>The semantic score is high</li>
<li>If you expand the document accordion - there is a lot of text returned in this passage</li>
</ul>
<p>In the next example, we've set the maximum allowed documents to three with snippet size set to 400 (relatively small):</p>
<p><a class="glightbox" href="../images/3_doc_400_snippet_size.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/3_doc_400_snippet_size.png" /></a>
<a class="glightbox" href="../images/seek_with_2_doc_max.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/seek_with_2_doc_max.png" /></a></p>
<p>We now have:</p>
<ul>
<li>One additional document (total of 2)</li>
<li>A lower semantic score</li>
<li>More source jumps in the answer</li>
</ul>
<p>Generally speaking, and for most use cases, it is better to provide a few top quality documents, versus many low quality or unrelated documents, to the LLM for answer generation. Using these settings can help focus or widen the documentation as needed per use-case.</p>
<h3 id="optimal-settings">Optimal Settings<a class="headerlink" href="#optimal-settings" title="Permanent link"></a></h3>
<p>For most use-cases, the combination of settings that we get the best results with are close to:</p>
<p><strong>In KB Tuning:</strong></p>
<ul>
<li>Document Score Range: <code>0.6 - 0.8</code></li>
<li>Max Documents per Seek: <code>4 - 5</code></li>
<li>Snippet Size: If your documents are mostly filled with unrelated small paragraphs (2-3 sentences) - like an faq document - then <code>400 - 600</code> is appropriate. Note it is always best to break up documents containing unrelated information into multiple documents. If your documents are large reference manuals that contain long passages - use the max snippet size available to you.</li>
</ul>
<p><strong>In Answer Engineering:</strong></p>
<ul>
<li><code>Answer Verbosity</code> slider favoring the "Very Concise" side</li>
<li>Enable <code>Force Answers from the KnowledgeBase</code></li>
</ul>
<p><strong>In Governance and Guardrails:</strong></p>
<ul>
<li><code>Warning Confidence</code> around +/- 20%</li>
<li><code>Minimum Confidence</code> around +/- 10-20%</li>
<li><code>Minimum Text</code> around 1-3 words</li>
<li><code>Maximum Length</code> around 20 words</li>
</ul>
<h3 id="improving-source-documentation">Improving Source Documentation<a class="headerlink" href="#improving-source-documentation" title="Permanent link"></a></h3>
<p>One of the best ways to directly improve answer generation! Here's an example:</p>
<ul>
<li>A customer had a very large document, with an Acronym and a definition that was near the top of the document. The acronym was used hundreds of times across many pages. The source KB typically returned the paragraph with the most uses (matches) of the acronym, despite the overall snippet not answering the question directly. To improve the results, we split the document by pages, increased the score range and lowered the snippet size, allowing the KB to effortlessly bring back the relevant document passages while enabling the customer to control the amount of documentation fed to the LLM.</li>
</ul>
<p>Generally speaking, the best practice for source documentation formatting is to have <strong>individual documents that speak directly to the subject you want to answer</strong>.</p>
<h3 id="hybrid-and-vector-search">Hybrid and Vector Search<a class="headerlink" href="#hybrid-and-vector-search" title="Permanent link"></a></h3>
<p>NeuralSeek supports Vector searching on some KnowledgeBase platforms. (see the Supported KnowledgeBases page for details)</p>
<p><a class="glightbox" href="../images/hybrid_vector.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/hybrid_vector.png" /></a></p>
<p>Vector Similarity searching is finding "similar" words, where Lucene is "exact matching" terms. For example, if you search for <code>Animal</code> you could also get results like <code>Cat, Dog, Mouse, Lizard</code>. It's not recommended to use only vector search for corporate-based RAG, as the chance of hallucination is incredibly high. For example - a user searches for <code>8.1.0</code>. Lucene will bring back only results with the exact term, where vector similarity may also return <code>8.0.1</code>, <code>8.10</code>, or similar.</p>
<p>Choosing the Hybrid implementation is recommended if using vector similarity - NeuralSeek will boost the Lucene results, offering Vector results as a sort of "fallback". This can help some use cases. Pure vector serach is not reccomended in any RAG pattern as any vector search increases the likelihood of halucinations.</p>
<h3 id="answer-variations">Answer Variations<a class="headerlink" href="#answer-variations" title="Permanent link"></a></h3>
<p>Generative AI often times will generate small variations for the same query.</p>
<p>Two ways to combat this:</p>
<ul>
<li>Set the "edited" answer cache setting to 1, and edit the answer on the curate tab.</li>
<li>Set the "normal" answer cache setting to 1. </li>
</ul>
<p>Both of these options will cause NeuralSeek to output consistent, identical answers. This also reduces the amount of language generation calls.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Edited answers always return a Semantic Score of 100%.  </p>
</div>
<h2 id="filtering-documentation">Filtering Documentation<a class="headerlink" href="#filtering-documentation" title="Permanent link"></a></h2>
<p>Many times there is a large amount of documents, or many data sources / types, to manage. Filtering can narrow down results in a large pool of data.</p>
<p>You may filter on any metadata field available from the KB. Simply set the desired field in the KnowledgeBase Connection settings, and pass a value for which to filter in the Seek call. </p>
<p>For example - Using <code>metadata.document_type</code> as the field, and <code>PDF</code> as the value, will return only documents with this field set to PDF. Use comma-separated values for an <code>OR</code> filter.</p>
<div class="admonition note">
<p class="admonition-title">Watson Discovery users</p>
<p>To filter by Collection ID: Under KnowledgeBase Connection, enable the Advanced Schema, and manually input <code>collection_id</code> in the filter field</p>
<p>DQL_Pushdown is also an option for Discovery users - Select this option, and pass <a href="https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-dql-overview">DQL syntax</a> in the filter value on Seek calls.</p>
</div>
<p>Another tool to help target the best quality documentation available is to utilize the "Re-Sort values list" option. This allows you to prioritize certain documents over others - maybe use a collection ID to prioritize internal uploaded documentation over a general company website scrape, or perhaps PDFs have more concise data than your DOCX files. <strong>This allows you to prioritize values without entirely excluding other values.</strong></p>
<h2 id="avoiding-timeouts">Avoiding Timeouts<a class="headerlink" href="#avoiding-timeouts" title="Permanent link"></a></h2>
<p>NeuralSeek has a limited amount of time to generate a response, as well as a context window that the LLM dictates. Sometimes, the LLM generates large answers and cannot finish its thought before the space runs out, we exceed the chatbot platform timeout, or we exceed the KB's timeout. This will occasionally cause the generated answer to have a dangling sentence near the end - NeuralSeek looks for these dangling responses and trims them back to a logical sentence.</p>
<p>Contributing factors can include:</p>
<ul>
<li>KnowledgeBase retrieval speed</li>
<li>LLM generation speed</li>
<li>Chatbot settings - timeout settings, etc</li>
<li>Network latency</li>
</ul>
<p>Some settings that may help:</p>
<ul>
<li>Reducing the maximum number of documents returned from the KB</li>
<li>Using a faster LLM</li>
<li>Reducing LLM verbosity in the NeuralSeek Configuration</li>
<li>Increasing the chatbot timeout threshold</li>
<li>Provisioning services in the same regions</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When adjusting the verbosity setting, for shorter answers change the verbosity setting to "more concise". For longer/more descriptive answers change the verbosity setting to "more verbose".</p>
</div>
<h2 id="knowledgebase-translation">KnowledgeBase Translation<a class="headerlink" href="#knowledgebase-translation" title="Permanent link"></a></h2>
<p>It can be challenging to work with multiple languages. For example - you want the LLM to respond in Spanish, but the source documentation is in English. NeuralSeek can solve this: In the Platform Preferences configuration, enable <code>Translate into KB Language</code>, and set the desired output language. </p>
<p><a class="glightbox" href="../images/platform_preferences.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/platform_preferences.png" /></a></p>
<p>This allows NeuralSeek to:</p>
<ul>
<li>Accept a question in Spanish (for example)</li>
<li>Translate to English (source documentation language)</li>
<li>Perform a KB search in English</li>
<li>Generate an Answer in English</li>
<li>Translate the Answer to Spanish</li>
</ul>
<div class="admonition warning">
<p class="admonition-title">For Bring-your-own LLM users</p>
<p>When using the cross-language feature of NeuralSeek, some LLMs will not excel at this. You will need to use a powerful model like GPT, Llama 70b, or Mixtral.</p>
</div>
<p>You can set NeuralSeek's output language to "Match Input" to respond in the same language as the query. Another choice is to have the chatbot control the language returned. Some chatbots support passing the language dynamically as a context variable to the NeuralSeek API. The source of the context variable can be the web browser language or part of the chatbot's URL that tells you the user's language.</p>
<p>Example from watsonx Assistant:</p>
<p><a class="glightbox" href="../images/extension_config.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Click_to_insert" src="../images/extension_config.png" /></a></p>
<h2 id="using-multiple-data-sources">Using Multiple Data Sources<a class="headerlink" href="#using-multiple-data-sources" title="Permanent link"></a></h2>
<p>NeuralSeek allows you to use multiple configurations on-demand, effectively overriding any settings currently in the Configure tab. This is useful if you want to use multiple KB sources, project IDs, or similarly exceed the UI limitations.</p>
<p><a class="glightbox" href="../images/download_settings.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="download settings" src="../images/download_settings.png" /></a></p>
<p>Simply configure NeuralSeek with the desired parameters, save, and then "Download Settings" as pictured.</p>
<p>This will download a <code>.dat</code> file, containing an encoded string of all current settings - including KB details, project IDs, LLMs, etc.</p>
<p>On Seek API calls, set <code>options.override</code> to this encoded string - Effectively using these saved settings for this Seek call, ignoring "current" settings in the UI.</p>

          <br>
          <footer class="wm-footer">
                <p>Ⓒ 2024 NeuralSeek, all rights reserved.</p>
          </footer>
        </div>
      <br>
    </div>
  </div>
</div>




<script src="../../../../scripts/watson.js"></script>
<script> 
  function isInFrame() {
    return (window.top !== window);
  }
  if (!isInFrame()) {
    loadWatson(); 
  }
</script>
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
</script></body>
</html>